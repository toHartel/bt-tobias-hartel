{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset 2: Fictional Student Performance**\n",
    "\n",
    "In this notebook we'll go through the entire process of exploratory data analysis, synthetic data generation (SDG) and evaluation for Dataset 2: Fictional Student Performance.\n",
    "\n",
    "The evaluation approach that is used was suggested by  Liu et al. [1]. The goal is to provide a comprehensive evaluation for synthetic tabular data in learning analytics that encompasses utility, resemblance and privacy metrics. The dataset used in this notebook was generated by Roice Kimmons and contains 1000 entries of student data.\n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasets/spscientist/students-performance-in-exams/data\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] Qinyi Liu, Mohammad Khalil, Ronas Shakya, and Jelena Jovanovic. 2024.\n",
    "Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular\n",
    "Data Generation and Evaluation in Learning Analytics. In The 14th Learning\n",
    "Analytics and Knowledge Conference (LAK ’24), March 18–22, 2024, Kyoto,\n",
    "Japan. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3636555.\n",
    "3636921"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**\n",
    "First, import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from generation.data_synthesizer import ds_generate_data\n",
    "from generation.synthetic_data_vault import sdv_generate_data\n",
    "from evaluation.utility import run_utility_eval\n",
    "from evaluation.resemblance import pairwise_correlation_diff, jsd, wd\n",
    "from evaluation.privacy import dcr, nndr, mia\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**\n",
    "Let's take a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset as dataframe\n",
    "data_path = \"../data/original_data/2_fictional_students_performance/2_fictional_students_performance.csv\"\n",
    "original_data = pd.read_csv(data_path)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race/ethnicity               1000 non-null   object\n",
      " 2   parental level of education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test preparation course      1000 non-null   object\n",
      " 5   math score                   1000 non-null   int64 \n",
      " 6   reading score                1000 non-null   int64 \n",
      " 7   writing score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get general information about the dataset\n",
    "original_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         0\n",
       "race/ethnicity                 0\n",
       "parental level of education    0\n",
       "lunch                          0\n",
       "test preparation course        0\n",
       "math score                     0\n",
       "reading score                  0\n",
       "writing score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "original_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, no missing values.\n",
    "\n",
    "Let's see how many unique values there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                          2\n",
       "race/ethnicity                  5\n",
       "parental level of education     6\n",
       "lunch                           2\n",
       "test preparation course         2\n",
       "math score                     81\n",
       "reading score                  72\n",
       "writing score                  77\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of unique values in each column\n",
    "original_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save categorical columns for encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender ['female' 'male']\n",
      "race/ethnicity ['group B' 'group C' 'group A' 'group D' 'group E']\n",
      "parental level of education [\"bachelor's degree\" 'some college' \"master's degree\" \"associate's degree\"\n",
      " 'high school' 'some high school']\n",
      "lunch ['standard' 'free/reduced']\n",
      "test preparation course ['none' 'completed']\n"
     ]
    }
   ],
   "source": [
    "# Check categorical columns\n",
    "categorical_cols = original_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(col, original_data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Synthetic Data Generation**\n",
    "\n",
    "Now we'll prepare for SDG and split up the original data into 30/70 test/train splits. If the splits were created earlier already, we will load the existing splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data loaded.\n"
     ]
    }
   ],
   "source": [
    "original_data_path = \"../data/original_data/2_fictional_students_performance/\"\n",
    "train_file = os.path.join(original_data_path, \"train_data.csv\")\n",
    "test_file = os.path.join(original_data_path, \"test_data.csv\")\n",
    "\n",
    "if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    print(\"Train and test data loaded.\")\n",
    "else:\n",
    "    # Split the data into train and test sets (70% train, 30% test) according to evaluation paper\n",
    "    train_data, test_data = train_test_split(original_data, test_size=0.3, random_state=42)\n",
    "    train_data.to_csv(train_file, index=False)\n",
    "    test_data.to_csv(test_file, index=False)\n",
    "    print(\"Train and test data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check whether the synthetic datasets were already generated. If not, use the train split to train the SDG models and sample as many entries as the train dataset contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data already exists.\n"
     ]
    }
   ],
   "source": [
    "# Set the start method of the multiprocessing module to 'fork' to avoid an error\n",
    "multiprocessing.set_start_method('fork', force=True)\n",
    "\n",
    "# Set path where synthetic data will be saved\n",
    "synth_path = \"../data/synthetic_data/2_fictional_students_performance/\"\n",
    "csv_files = [file for file in os.listdir(synth_path) if file.endswith(\".csv\")]\n",
    "dataset_name = '2_fictional_students_performance'\n",
    "\n",
    "# Number of samples to generate\n",
    "n = len(train_data)\n",
    "\n",
    "if len(csv_files) == 0:\n",
    "\n",
    "    # Use train_data.csv to fit SDG models and generate synthetic data\n",
    "    data_path = original_data_path + \"train_data.csv\"\n",
    "    # Set up arguments to pass to the R script\n",
    "    arguments = [data_path, str(n), dataset_name]\n",
    "\n",
    "    print(\"Fit models and create synthetic data:\")\n",
    "    print(\"Sampling synthpop...\")\n",
    "    result = subprocess.run(['Rscript', '../src/generation/synthpop.R',   *arguments], capture_output=True, text=True)\n",
    "\n",
    "    print(\"\\nDataSynthesizer...\")\n",
    "    ds_generate_data(data_path=data_path, num_samples=n, dataset_name=dataset_name)\n",
    "\n",
    "    print(\"\\nSDV...\")\n",
    "    sdv_generate_data(data_path=data_path, num_samples=n, dataset_name=dataset_name)\n",
    "\n",
    "    print(\"\\nSynthetic data generated.\")\n",
    "else:\n",
    "    print(\"Synthetic data already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the synthetic dataset and encode all categorical columns of both original (train+test) data and synthetic data using label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic data as dataframe\n",
    "synthpop = pd.read_csv(synth_path + \"synthpop.csv\")\n",
    "ds = pd.read_csv(synth_path + \"ds.csv\")\n",
    "tvae = pd.read_csv(synth_path + \"tvae.csv\")\n",
    "gaussian_copula = pd.read_csv(synth_path + \"gaussian_copula.csv\")\n",
    "copula_gan = pd.read_csv(synth_path + \"copula_gan.csv\")\n",
    "ctgan = pd.read_csv(synth_path + \"ctgan.csv\")\n",
    "\n",
    "# Encode categorical columns as integers\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    test_data[col] = le.fit_transform(test_data[col])\n",
    "\n",
    "    synthpop[col] = le.fit_transform(synthpop[col])\n",
    "    ds[col] = le.fit_transform(ds[col])\n",
    "    tvae[col] = le.fit_transform(tvae[col])\n",
    "    gaussian_copula[col] = le.fit_transform(gaussian_copula[col])\n",
    "    copula_gan[col] = le.fit_transform(copula_gan[col])\n",
    "    ctgan[col] = le.fit_transform(ctgan[col])\n",
    "\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   gender                       700 non-null    int64  \n",
      " 1   race/ethnicity               700 non-null    int64  \n",
      " 2   parental level of education  700 non-null    int64  \n",
      " 3   lunch                        700 non-null    int64  \n",
      " 4   test preparation course      700 non-null    int64  \n",
      " 5   math score                   700 non-null    float64\n",
      " 6   reading score                700 non-null    float64\n",
      " 7   writing score                700 non-null    float64\n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 43.9 KB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_datasets = [synthpop, ds, tvae, gaussian_copula, copula_gan, ctgan]\n",
    "model_names = [\"synthpop\", \"ds\", \"tvae\", \"gaussian_copula\", \"copula_gan\", \"ctgan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resemblance**\n",
    "\n",
    "The resemblance dimension includes mutliple distance metrics to measure the similarity of the synthetic and real data: **Difference in pairwise correlation, Jensen-Shannon divergence, Wasserstein distance**\n",
    "\n",
    "- **Difference in pairwise correlation** is used to measure how well feature-interactions are preserved within synthetic data. First the pairwise correlation matrices for each real and synthetic data is computed. Pearson correlation coefficient is used for continuous features ( [-1,1] range) and the Theil uncer-\n",
    "tainty coefficient ([0,1] range) for categorical features\n",
    "    - lower (difference) values are better\n",
    "- **JSD** is a method for measuring similarity between two probability distributions. It is based on Kullback-Leibler divergence, but has several benefits like being symmetric and having finite values. Values are bounded between 0 and 1, where values close to 0 indicate high similarity and values close to 1 indicate almost no similarity between the distributions.\n",
    "    - lower values are better\n",
    "- **WD** is used to compare the distributions of two continuous/mixed variables, where one variable is derived from the other → how well the synthetic data emulates the distribution of the\n",
    "individual variables\n",
    "    - lower values are better\n",
    "\n",
    "\n",
    "**Difference in pairwise correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Pairwise Corr Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>0.024836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ds</td>\n",
       "      <td>0.177231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tvae</td>\n",
       "      <td>0.166282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_copula</td>\n",
       "      <td>0.069194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>copula_gan</td>\n",
       "      <td>0.197659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.193518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset            Model  Pairwise Corr Diff\n",
       "0        2         synthpop            0.024836\n",
       "1        2               ds            0.177231\n",
       "2        2             tvae            0.166282\n",
       "3        2  gaussian_copula            0.069194\n",
       "4        2       copula_gan            0.197659\n",
       "5        2            ctgan            0.193518"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_diff_df = pd.read_csv(\"../data/results/tables/corr_diff.csv\")\n",
    "rows = []\n",
    "\n",
    "if (corr_diff_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = pairwise_correlation_diff(train_data, synth_dataset)\n",
    "        rows.append([2,model_names[i], result])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=corr_diff_df.columns)\n",
    "    corr_diff_df = pd.concat([corr_diff_df, rows])\n",
    "    corr_diff_df.to_csv(\"../data/results/tables/corr_diff.csv\", index=False)\n",
    "\n",
    "corr_diff_df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jensen-Shannon Divergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>JSD Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>0.006083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ds</td>\n",
       "      <td>0.059914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tvae</td>\n",
       "      <td>0.076419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_copula</td>\n",
       "      <td>0.010896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>copula_gan</td>\n",
       "      <td>0.039251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.049533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset            Model  JSD Diff\n",
       "0        2         synthpop  0.006083\n",
       "1        2               ds  0.059914\n",
       "2        2             tvae  0.076419\n",
       "3        2  gaussian_copula  0.010896\n",
       "4        2       copula_gan  0.039251\n",
       "5        2            ctgan  0.049533"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsd_df = pd.read_csv(\"../data/results/tables/jsd.csv\")\n",
    "rows = []\n",
    "\n",
    "if (jsd_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = jsd(train_data, synth_dataset)\n",
    "        rows.append([2,model_names[i], result])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=jsd_df.columns)\n",
    "    jsd_df = pd.concat([jsd_df, rows])\n",
    "    jsd_df.to_csv(\"../data/results/tables/jsd.csv\", index=False)\n",
    "\n",
    "jsd_df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wasserstein Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>WD Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>0.006857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ds</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tvae</td>\n",
       "      <td>0.091917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_copula</td>\n",
       "      <td>0.008848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>copula_gan</td>\n",
       "      <td>0.030629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset            Model   WD Diff\n",
       "0        2         synthpop  0.006857\n",
       "1        2               ds  0.047000\n",
       "2        2             tvae  0.091917\n",
       "3        2  gaussian_copula  0.008848\n",
       "4        2       copula_gan  0.030629\n",
       "5        2            ctgan  0.018900"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_df = pd.read_csv(\"../data/results/tables/wd.csv\")\n",
    "rows = []\n",
    "\n",
    "if (wd_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = wd(train_data, synth_dataset)\n",
    "        rows.append([2,model_names[i],result])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=wd_df.columns)\n",
    "    wd_df = pd.concat([wd_df, rows])\n",
    "    wd_df.to_csv(\"../data/results/tables/wd.csv\", index=False)\n",
    "    \n",
    "wd_df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for synthpop...\n",
      "Property  Data Validity  Data Structure  Column Shapes  Column Pair Trends\n",
      "Score               1.0             1.0       0.974821            0.934377 \n",
      "\n",
      "Calculating metrics for ds...\n",
      "Property  Data Validity  Data Structure  Column Shapes  Column Pair Trends\n",
      "Score               1.0             1.0         0.7975            0.663953 \n",
      "\n",
      "Calculating metrics for tvae...\n",
      "Property  Data Validity  Data Structure  Column Shapes  Column Pair Trends\n",
      "Score               1.0             1.0       0.801607            0.603936 \n",
      "\n",
      "Calculating metrics for gaussian_copula...\n",
      "Property  Data Validity  Data Structure  Column Shapes  Column Pair Trends\n",
      "Score               1.0             1.0       0.968929            0.886784 \n",
      "\n",
      "Calculating metrics for copula_gan...\n",
      "Property  Data Validity  Data Structure  Column Shapes  Column Pair Trends\n",
      "Score               1.0             1.0       0.843393             0.74225 \n",
      "\n",
      "Calculating metrics for ctgan...\n",
      "Property  Data Validity  Data Structure  Column Shapes  Column Pair Trends\n",
      "Score               1.0             1.0       0.861607            0.749113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluation.sd_metrics import sd_metrics\n",
    "\n",
    "\n",
    "for i, synth_dataset in enumerate(synth_datasets):\n",
    "    print(f\"Calculating metrics for {model_names[i]}...\")\n",
    "    print(sd_metrics(train_data, synth_dataset), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Privacy**\n",
    "\n",
    "To assess the privacy aspect of the synthetic data the metrics **Distance to closest Record (DCR)**, **Nearest Neighbour Difference Ratio (NNDR)** and **Membership Inference Attack (MIA)** will be used. \n",
    "\n",
    "- In **DCR** the euclidean distance between\n",
    "each record in original and synthetic dataset is computed. DCR is the minimum distance between a synthetic record and a original record. \n",
    "    - A value of zero indicates that the synthetic record is an identical copy of the original one -> leak of real information, higher values indicate more privacy\n",
    "\n",
    "- **NNDR** is ratio between nearest and second nearest real neighbour to any corresponding synthetic record (NNDR(s) = d1/d2) and is within [0,1]\n",
    "    - higher values indicate better privacy\n",
    "\n",
    "- **MIA** is used to assess the disclosure risk by assuming that an attacker has access to all the records of the synthetic data and to a random subset of the original data. Using a real record the attacker then tries to find the closest record in the synthetic dataset. If there is any distance below some threshold, the attacker can assume that the corresponding real record was used to generate the synthetic data.\n",
    "    - For strong privacy preservation both accuracy and precision should be below 0.5 for all thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance to closest record (DCR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.414\n",
      "3.873\n",
      "2.0\n",
      "1.732\n",
      "3.457\n",
      "3.154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>DCR 5th Percentile</th>\n",
       "      <th>DCR 5th Percentile (within Real)</th>\n",
       "      <th>DCR 5th Percentile (within Synthetic)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.732</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ds</td>\n",
       "      <td>3.873</td>\n",
       "      <td>1.732</td>\n",
       "      <td>2.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tvae</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.732</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_copula</td>\n",
       "      <td>1.732</td>\n",
       "      <td>1.732</td>\n",
       "      <td>1.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>copula_gan</td>\n",
       "      <td>3.457</td>\n",
       "      <td>1.732</td>\n",
       "      <td>2.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>3.154</td>\n",
       "      <td>1.732</td>\n",
       "      <td>2.236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset            Model  DCR 5th Percentile  \\\n",
       "0        2         synthpop               1.414   \n",
       "1        2               ds               3.873   \n",
       "2        2             tvae               2.000   \n",
       "3        2  gaussian_copula               1.732   \n",
       "4        2       copula_gan               3.457   \n",
       "5        2            ctgan               3.154   \n",
       "\n",
       "   DCR 5th Percentile (within Real)  DCR 5th Percentile (within Synthetic)  \n",
       "0                             1.732                                  1.414  \n",
       "1                             1.732                                  2.449  \n",
       "2                             1.732                                  1.414  \n",
       "3                             1.732                                  1.732  \n",
       "4                             1.732                                  2.828  \n",
       "5                             1.732                                  2.236  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dcr_df = pd.read_csv(\"../data/results/tables/dcr.csv\")\n",
    "rows = []\n",
    "\n",
    "if (dcr_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = dcr(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, save_hist=True)\n",
    "        print(result)\n",
    "        result_within_real = dcr(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, within=\"Original\")\n",
    "        result_within_synth = dcr(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, within=\"Synthetic\")\n",
    "        rows.append([2,model_names[i], result, result_within_real, result_within_synth])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=dcr_df.columns)\n",
    "    dcr_df = pd.concat([dcr_df, rows])\n",
    "    dcr_df.to_csv(\"../data/results/tables/dcr.csv\", index=False)\n",
    "\n",
    "dcr_df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nearest Neighbor distance ratio (NNDR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>NNDR 5th percentile</th>\n",
       "      <th>NNDR 5th percentile (within Real)</th>\n",
       "      <th>NNDR 5th percentile (within Synthetic)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ds</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tvae</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_copula</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>copula_gan</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset            Model  NNDR 5th percentile  \\\n",
       "0        2         synthpop                0.408   \n",
       "1        2               ds                0.756   \n",
       "2        2             tvae                0.577   \n",
       "3        2  gaussian_copula                0.555   \n",
       "4        2       copula_gan                0.745   \n",
       "5        2            ctgan                0.729   \n",
       "\n",
       "   NNDR 5th percentile (within Real)  NNDR 5th percentile (within Synthetic)  \n",
       "0                              0.555                                   0.425  \n",
       "1                              0.555                                   0.371  \n",
       "2                              0.555                                   0.458  \n",
       "3                              0.555                                   0.577  \n",
       "4                              0.555                                   0.500  \n",
       "5                              0.555                                   0.513  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndr_df = pd.read_csv(\"../data/results/tables/nndr.csv\")\n",
    "rows = []\n",
    "\n",
    "if (nndr_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = nndr(train_data, synth_dataset)\n",
    "        result_within_real = nndr(train_data, synth_dataset, within=\"Original\")\n",
    "        result_within_synth = nndr(train_data, synth_dataset, within=\"Synthetic\")\n",
    "        rows.append([2,model_names[i], result, result_within_real, result_within_synth])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=nndr_df.columns)\n",
    "    nndr_df = pd.concat([nndr_df, rows])\n",
    "    nndr_df.to_csv(\"../data/results/tables/nndr.csv\", index=False)\n",
    "\n",
    "nndr_df.tail(6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membership Inference Attack (MIA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIA results already exist.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "mia_results = {}\n",
    "mia_path = \"../data/results/plots/mia/2_fictional_students_performance/\"\n",
    "mia_files = glob.glob(os.path.join(mia_path, \"*.png\"))\n",
    "if (mia_files):\n",
    "    print(\"MIA results already exist.\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        mia_results[model_names[i]] = mia(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, save_plts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Proportion</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset     Model     Metric  Threshold  Proportion  Value\n",
       "0       1  synthpop  precision        0.1         0.2    0.0\n",
       "1       1  synthpop  precision        0.1         0.3    0.0\n",
       "2       1  synthpop  precision        0.1         0.4    0.0\n",
       "3       1  synthpop  precision        0.1         0.5    0.0\n",
       "4       1  synthpop  precision        0.1         0.6    0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "rows = []\n",
    "for model, metrics in mia_results.items():\n",
    "    for metric, thresholds in metrics.items():\n",
    "        for threshold, values in thresholds.items():\n",
    "            for proportion, value in zip(proportions, values):\n",
    "                rows.append([2,model, metric, threshold, proportion, value])\n",
    "                \n",
    "mia_df = pd.read_csv(\"../data/results/tables/mia.csv\")\n",
    "rows = pd.DataFrame(rows, columns=mia_df.columns)\n",
    "mia_df = pd.concat([mia_df, rows])\n",
    "mia_df.to_csv(\"../data/results/tables/mia.csv\", index=False)\n",
    "mia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Utility**\n",
    "\n",
    "In order to evaluate the utility of the synthetic datasets, the following steps will executed three times, each time with a different ML model.\n",
    "\n",
    "1. Two models are trained: one using the original train data and the other one using synthetic data.\n",
    "2. The two different models will predict the target column using the test split.\n",
    "3. The difference in performance between the two models will be reported via accuracy diff, f1-score diff, and auc-roc diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the columns 'math score', 'reading score' and 'writing score' to new column 'result', which contains the average of all three scores. Then, to simplify classification, bin the result into three categories labelled with 0,1,2 (failed, passed, excellent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target column\n",
    "target_col = \"result\"\n",
    "\n",
    "# Prepare datasets for utility evalutation\n",
    "#  Add a column for average of math, reading and writing scores for each dataset and cut the values into five classes\n",
    "train_data[target_col] = train_data[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
    "test_data[target_col] = test_data[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
    "\n",
    "quantiles = train_data[target_col].quantile([0, 0.2, 0.4, 0.6, 0.8, 1]).values\n",
    "\n",
    "train_data[target_col] = pd.cut(train_data[target_col], bins=quantiles, labels=[0, 1, 2, 3, 4], include_lowest=True)\n",
    "train_data.drop(['math score', 'reading score', 'writing score'], axis=1, inplace=True)\n",
    "test_data[target_col] = pd.cut(test_data[target_col], bins=quantiles, labels=[0, 1, 2, 3, 4], include_lowest=True)\n",
    "test_data.drop(['math score', 'reading score', 'writing score'], axis=1, inplace=True)\n",
    "\n",
    "for synth_dataset in synth_datasets:\n",
    "    synth_dataset[target_col] = synth_dataset[['math score', 'reading score', 'writing score']].mean(axis=1)\n",
    "    synth_dataset[target_col] = pd.cut(synth_dataset[target_col], bins=quantiles, labels=[0, 1, 2, 3, 4], include_lowest=True)\n",
    "    synth_dataset.drop(['math score', 'reading score', 'writing score'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gender  race/ethnicity  parental level of education  lunch  \\\n",
      "39       0               2                            5      0   \n",
      "\n",
      "    test preparation course result  \n",
      "39                        1    NaN  \n"
     ]
    }
   ],
   "source": [
    "print(test_data[test_data[target_col].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[target_col] = test_data[target_col].fillna(test_data[target_col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[target_col].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "0    75\n",
      "1    65\n",
      "3    64\n",
      "4    51\n",
      "2    45\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='result', ylabel='Count'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(test_data['result'].value_counts())\n",
    "sns.histplot(test_data['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         2\n",
       "race/ethnicity                 4\n",
       "parental level of education    5\n",
       "lunch                          2\n",
       "test preparation course        2\n",
       "result                         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvae.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `random forest classifier` for utility evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         2\n",
       "race/ethnicity                 5\n",
       "parental level of education    6\n",
       "lunch                          2\n",
       "test preparation course        2\n",
       "result                         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Difference</th>\n",
       "      <th>F1 Score Difference</th>\n",
       "      <th>ROC AUC Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>synthpop</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ds</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tvae</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_copula</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>copula_gan</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>ctgan</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset            Model  Accuracy Difference  F1 Score Difference  \\\n",
       "5        1            ctgan                 0.39                 0.38   \n",
       "0        2         synthpop                -0.02                -0.03   \n",
       "1        2               ds                 0.03                 0.05   \n",
       "2        2             tvae                 0.00                -0.02   \n",
       "3        2  gaussian_copula                 0.01                 0.01   \n",
       "4        2       copula_gan                 0.05                 0.06   \n",
       "5        2            ctgan                 0.02                 0.06   \n",
       "\n",
       "   ROC AUC Difference  \n",
       "5                0.28  \n",
       "0               -0.02  \n",
       "1                0.04  \n",
       "2               -0.06  \n",
       "3                0.03  \n",
       "4                0.06  \n",
       "5                0.01  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results = {}\n",
    "rf_df = pd.read_csv(\"../data/results/tables/rf.csv\")\n",
    "rows = []\n",
    "\n",
    "if (rf_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "    # Run utility evaluation using random forest for each synthetic dataset\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        rf_results[model_names[i]] = run_utility_eval(train_data, test_data, synth_dataset, target_col, \"random_forest\")\n",
    "\n",
    "        acc_diff = rf_results[model_names[i]][\"acc_diff\"]\n",
    "        f1_diff = rf_results[model_names[i]][\"f1_diff\"]\n",
    "        roc_auc_diff = rf_results[model_names[i]][\"roc_auc_diff\"]\n",
    "\n",
    "        rows.append([2, model_names[i], acc_diff, f1_diff, roc_auc_diff])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=rf_df.columns)\n",
    "    rf_df = pd.concat([rf_df, rows])\n",
    "    rf_df.to_csv(\"../data/results/tables/rf.csv\", index=False)\n",
    "\n",
    "\n",
    "rf_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `logistic regression` for utility evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = {}\n",
    "lr_df = pd.read_csv(\"../data/results/tables/lr.csv\")\n",
    "rows = []\n",
    "\n",
    "if (lr_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "# Run utility evaluation using logistic regression for each synthetic dataset\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        lr_results[model_names[i]] = run_utility_eval(train_data, test_data, synth_dataset, target_col, \"logistic_regression\")\n",
    "\n",
    "        acc_diff = lr_results[model_names[i]][\"acc_diff\"]\n",
    "        f1_diff = lr_results[model_names[i]][\"f1_diff\"]\n",
    "        roc_auc_diff = lr_results[model_names[i]][\"roc_auc_diff\"]\n",
    "\n",
    "        rows.append([2, model_names[i], acc_diff, f1_diff, roc_auc_diff])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=lr_df.columns)\n",
    "    lr_df = pd.concat([lr_df, rows])\n",
    "    lr_df.to_csv(\"../data/results/tables/lr.csv\", index=False)\n",
    "    lr_df.tail(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `multilayer perceptron` (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_results = {}\n",
    "mlp_df = pd.read_csv(\"../data/results/tables/mlp.csv\")\n",
    "rows = []\n",
    "\n",
    "if (mlp_df[\"Dataset\"] == 2).any():\n",
    "    print(\"Entry for '2_fictional_students' already exists\")\n",
    "else:\n",
    "# Run utility evaluation using multilayer perceptron for each synthetic dataset\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        mlp_results[model_names[i]] = run_utility_eval(train_data, test_data, synth_dataset, target_col, \"multilayer_perceptron\")\n",
    "\n",
    "        acc_diff = mlp_results[model_names[i]][\"acc_diff\"]\n",
    "        f1_diff = mlp_results[model_names[i]][\"f1_diff\"]\n",
    "        roc_auc_diff = mlp_results[model_names[i]][\"roc_auc_diff\"]\n",
    "\n",
    "        rows.append([2, model_names[i], acc_diff, f1_diff, roc_auc_diff])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=mlp_df.columns)\n",
    "    mlp_df = pd.concat([mlp_df, rows])\n",
    "    mlp_df.to_csv(\"../data/results/tables/mlp.csv\", index=False)\n",
    "    mlp_df.tail(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt-sdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

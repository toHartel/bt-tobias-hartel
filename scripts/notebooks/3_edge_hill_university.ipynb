{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset 3: Edge Hill University**\n",
    "\n",
    "In this notebook we'll go through the entire process of exploratory data analysis, synthetic data generation (SDG) and evaluation for Dataset 3: Edge Hill University.\n",
    "\n",
    "The evaluation approach that is used was suggested by  Liu et al. [1]. The goal is to provide a comprehensive evaluation for synthetic tabular data in learning analytics that encompasses utility, resemblance and privacy metrics. The dataset used in this notebook is from students studying computer science at a University in the UK and consists of 80 Instances [2].\n",
    "\n",
    "Dataset source: https://data.mendeley.com/datasets/wf8568hxb7/1\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] Qinyi Liu, Mohammad Khalil, Ronas Shakya, and Jelena Jovanovic. 2024.\n",
    "Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular\n",
    "Data Generation and Evaluation in Learning Analytics. In The 14th Learning\n",
    "Analytics and Knowledge Conference (LAK ’24), March 18–22, 2024, Kyoto,\n",
    "Japan. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3636555.\n",
    "3636921\n",
    "\n",
    "[2] Nnamoko, Nonso; Barrowclough, Joe (2022), “Student grade prediction dataset”, Mendeley Data, V1, doi: 10.17632/wf8568hxb7.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from generation.data_synthesizer import ds_generate_data\n",
    "from generation.synthetic_data_vault import sdv_generate_data\n",
    "from evaluation.utility import run_utility_eval\n",
    "from evaluation.resemblance import pairwise_correlation_diff, jsd, wd\n",
    "from evaluation.privacy import dcr, nndr, mia\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>POLAR4 Quintile</th>\n",
       "      <th>POLAR3 Quintile</th>\n",
       "      <th>Adult HE 2001 Quintile</th>\n",
       "      <th>Adult HE 2011 Quintile</th>\n",
       "      <th>TUNDRA MSOA Quintile</th>\n",
       "      <th>TUNDRA LSOA Quintile</th>\n",
       "      <th>Gaps GCSE Quintile</th>\n",
       "      <th>Gaps GCSE Ethnicity Quintile</th>\n",
       "      <th>...</th>\n",
       "      <th>distance to university (km)</th>\n",
       "      <th>Count of Module Area Logins</th>\n",
       "      <th>Total Hours in Module Area</th>\n",
       "      <th>% of Average Hours in Module Area</th>\n",
       "      <th># of presence</th>\n",
       "      <th># of Absence</th>\n",
       "      <th>Percent Attended</th>\n",
       "      <th>label (fail=1, pass=0)</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.333806</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.620767</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.844126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.706573</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.514374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.327498</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.337610</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  POLAR4 Quintile  POLAR3 Quintile  Adult HE 2001 Quintile  \\\n",
       "0     0.0  38.0              5.0              5.0                     4.0   \n",
       "1     0.0  22.0              4.0              2.0                     1.0   \n",
       "2     0.0  21.0              4.0              5.0                     4.0   \n",
       "3     0.0  25.0              5.0              4.0                     3.0   \n",
       "4     0.0  20.0              5.0              4.0                     3.0   \n",
       "\n",
       "   Adult HE 2011 Quintile  TUNDRA MSOA Quintile  TUNDRA LSOA Quintile  \\\n",
       "0                     5.0                   4.0                   4.0   \n",
       "1                     3.0                   4.0                   4.0   \n",
       "2                     5.0                   4.0                   4.0   \n",
       "3                     4.0                   3.0                   3.0   \n",
       "4                     4.0                   3.0                   3.0   \n",
       "\n",
       "   Gaps GCSE Quintile   Gaps GCSE Ethnicity Quintile  ...  \\\n",
       "0                  5.0                           5.0  ...   \n",
       "1                  4.0                           5.0  ...   \n",
       "2                  5.0                           5.0  ...   \n",
       "3                  5.0                           5.0  ...   \n",
       "4                  4.0                           4.0  ...   \n",
       "\n",
       "   distance to university (km)  Count of Module Area Logins  \\\n",
       "0                    13.333806                         19.0   \n",
       "1                    15.844126                          1.0   \n",
       "2                    17.706573                         25.0   \n",
       "3                    17.327498                          3.0   \n",
       "4                     0.000000                         25.0   \n",
       "\n",
       "   Total Hours in Module Area  % of Average Hours in Module Area  \\\n",
       "0                        7.41                           0.620767   \n",
       "1                        0.03                           0.002513   \n",
       "2                        6.14                           0.514374   \n",
       "3                        0.16                           0.013404   \n",
       "4                        4.03                           0.337610   \n",
       "\n",
       "   # of presence  # of Absence  Percent Attended  label (fail=1, pass=0)  \\\n",
       "0            3.0           9.0         25.000000                     1.0   \n",
       "1            0.0          12.0          0.000000                     1.0   \n",
       "2            5.0           7.0         41.666667                     1.0   \n",
       "3            0.0          12.0          0.000000                     1.0   \n",
       "4           11.0           1.0         91.666667                     1.0   \n",
       "\n",
       "   Unnamed: 20  Unnamed: 21  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset as dataframe\n",
    "data_path = \"../data/original_data/3_edge_hill_university/3_edge_hill_university.csv\"\n",
    "original_data = pd.read_csv(data_path)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 22 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Gender                             80 non-null     float64\n",
      " 1   Age                                80 non-null     float64\n",
      " 2   POLAR4 Quintile                    80 non-null     float64\n",
      " 3   POLAR3 Quintile                    80 non-null     float64\n",
      " 4   Adult HE 2001 Quintile             80 non-null     float64\n",
      " 5   Adult HE 2011 Quintile             80 non-null     float64\n",
      " 6   TUNDRA MSOA Quintile               80 non-null     float64\n",
      " 7   TUNDRA LSOA Quintile               80 non-null     float64\n",
      " 8   Gaps GCSE Quintile                 80 non-null     float64\n",
      " 9   Gaps GCSE Ethnicity Quintile       80 non-null     float64\n",
      " 10  Uni Connect target ward            80 non-null     float64\n",
      " 11  attending from home?               80 non-null     float64\n",
      " 12  distance to university (km)        80 non-null     float64\n",
      " 13  Count of Module Area Logins        80 non-null     float64\n",
      " 14  Total Hours in Module Area         80 non-null     float64\n",
      " 15  % of Average Hours in Module Area  80 non-null     float64\n",
      " 16  # of presence                      80 non-null     float64\n",
      " 17  # of Absence                       78 non-null     float64\n",
      " 18  Percent Attended                   80 non-null     float64\n",
      " 19  label (fail=1, pass=0)             80 non-null     float64\n",
      " 20  Unnamed: 20                        0 non-null      float64\n",
      " 21  Unnamed: 21                        0 non-null      float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 15.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Get general information about the dataset\n",
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                                7\n",
       "Age                                   7\n",
       "POLAR4 Quintile                       7\n",
       "POLAR3 Quintile                       7\n",
       "Adult HE 2001 Quintile                7\n",
       "Adult HE 2011 Quintile                7\n",
       "TUNDRA MSOA Quintile                  7\n",
       "TUNDRA LSOA Quintile                  7\n",
       "Gaps GCSE Quintile                    7\n",
       "Gaps GCSE Ethnicity Quintile          7\n",
       "Uni Connect target ward               7\n",
       "attending from home?                  7\n",
       "distance to university (km)           7\n",
       "Count of Module Area Logins           7\n",
       "Total Hours in Module Area            7\n",
       "% of Average Hours in Module Area     7\n",
       "# of presence                         7\n",
       "# of Absence                          9\n",
       "Percent Attended                      7\n",
       "label (fail=1, pass=0)                7\n",
       "Unnamed: 20                          87\n",
       "Unnamed: 21                          87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "original_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>POLAR4 Quintile</th>\n",
       "      <th>POLAR3 Quintile</th>\n",
       "      <th>Adult HE 2001 Quintile</th>\n",
       "      <th>Adult HE 2011 Quintile</th>\n",
       "      <th>TUNDRA MSOA Quintile</th>\n",
       "      <th>TUNDRA LSOA Quintile</th>\n",
       "      <th>Gaps GCSE Quintile</th>\n",
       "      <th>Gaps GCSE Ethnicity Quintile</th>\n",
       "      <th>...</th>\n",
       "      <th>distance to university (km)</th>\n",
       "      <th>Count of Module Area Logins</th>\n",
       "      <th>Total Hours in Module Area</th>\n",
       "      <th>% of Average Hours in Module Area</th>\n",
       "      <th># of presence</th>\n",
       "      <th># of Absence</th>\n",
       "      <th>Percent Attended</th>\n",
       "      <th>label (fail=1, pass=0)</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.235646</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.68</td>\n",
       "      <td>0.475838</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.938766</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.59</td>\n",
       "      <td>1.306041</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.031985</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.30</td>\n",
       "      <td>1.365520</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender   Age  POLAR4 Quintile  POLAR3 Quintile  Adult HE 2001 Quintile  \\\n",
       "77     0.0  22.0              3.0              4.0                     3.0   \n",
       "78     1.0  21.0              5.0              4.0                     3.0   \n",
       "79     1.0  20.0              5.0              5.0                     4.0   \n",
       "80     NaN   NaN              NaN              NaN                     NaN   \n",
       "81     NaN   NaN              NaN              NaN                     NaN   \n",
       "82     NaN   NaN              NaN              NaN                     NaN   \n",
       "83     NaN   NaN              NaN              NaN                     NaN   \n",
       "84     NaN   NaN              NaN              NaN                     NaN   \n",
       "85     NaN   NaN              NaN              NaN                     NaN   \n",
       "86     NaN   NaN              NaN              NaN                     NaN   \n",
       "\n",
       "    Adult HE 2011 Quintile  TUNDRA MSOA Quintile  TUNDRA LSOA Quintile  \\\n",
       "77                     4.0                   3.0                   3.0   \n",
       "78                     4.0                   4.0                   4.0   \n",
       "79                     4.0                   3.0                   3.0   \n",
       "80                     NaN                   NaN                   NaN   \n",
       "81                     NaN                   NaN                   NaN   \n",
       "82                     NaN                   NaN                   NaN   \n",
       "83                     NaN                   NaN                   NaN   \n",
       "84                     NaN                   NaN                   NaN   \n",
       "85                     NaN                   NaN                   NaN   \n",
       "86                     NaN                   NaN                   NaN   \n",
       "\n",
       "    Gaps GCSE Quintile   Gaps GCSE Ethnicity Quintile  ...  \\\n",
       "77                  5.0                           5.0  ...   \n",
       "78                  4.0                           5.0  ...   \n",
       "79                  5.0                           5.0  ...   \n",
       "80                  NaN                           NaN  ...   \n",
       "81                  NaN                           NaN  ...   \n",
       "82                  NaN                           NaN  ...   \n",
       "83                  NaN                           NaN  ...   \n",
       "84                  NaN                           NaN  ...   \n",
       "85                  NaN                           NaN  ...   \n",
       "86                  NaN                           NaN  ...   \n",
       "\n",
       "    distance to university (km)  Count of Module Area Logins  \\\n",
       "77                    10.235646                         32.0   \n",
       "78                    56.938766                         35.0   \n",
       "79                    20.031985                         23.0   \n",
       "80                          NaN                          NaN   \n",
       "81                          NaN                          NaN   \n",
       "82                          NaN                          NaN   \n",
       "83                          NaN                          NaN   \n",
       "84                          NaN                          NaN   \n",
       "85                          NaN                          NaN   \n",
       "86                          NaN                          NaN   \n",
       "\n",
       "    Total Hours in Module Area  % of Average Hours in Module Area  \\\n",
       "77                        5.68                           0.475838   \n",
       "78                       15.59                           1.306041   \n",
       "79                       16.30                           1.365520   \n",
       "80                         NaN                                NaN   \n",
       "81                         NaN                                NaN   \n",
       "82                         NaN                                NaN   \n",
       "83                         NaN                                NaN   \n",
       "84                         NaN                                NaN   \n",
       "85                         NaN                                NaN   \n",
       "86                         NaN                                NaN   \n",
       "\n",
       "    # of presence  # of Absence  Percent Attended  label (fail=1, pass=0)  \\\n",
       "77           11.0           1.0         91.666667                     0.0   \n",
       "78            8.0           4.0         66.666667                     0.0   \n",
       "79            5.0           7.0         41.666667                     0.0   \n",
       "80            NaN           NaN               NaN                     NaN   \n",
       "81            NaN           NaN               NaN                     NaN   \n",
       "82            NaN           NaN               NaN                     NaN   \n",
       "83            NaN           NaN               NaN                     NaN   \n",
       "84            NaN           NaN               NaN                     NaN   \n",
       "85            NaN           NaN               NaN                     NaN   \n",
       "86            NaN           NaN               NaN                     NaN   \n",
       "\n",
       "    Unnamed: 20  Unnamed: 21  \n",
       "77          NaN          NaN  \n",
       "78          NaN          NaN  \n",
       "79          NaN          NaN  \n",
       "80          NaN          NaN  \n",
       "81          NaN          NaN  \n",
       "82          NaN          NaN  \n",
       "83          NaN          NaN  \n",
       "84          NaN          NaN  \n",
       "85          NaN          NaN  \n",
       "86          NaN          NaN  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: \n",
    "- 2 columns without any values\n",
    "- last 7 rows without any values\n",
    "- 2 additional missing values in column '# of Absence'\n",
    "\n",
    "Thus:\n",
    "- remove empty rows and columns and fill remaining missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "original_data.drop(['Unnamed: 20'], axis=1, inplace=True)\n",
    "original_data.drop(['Unnamed: 21'], axis=1, inplace=True)\n",
    "\n",
    "# Drop last 7 rows\n",
    "original_data.drop(original_data.tail(7).index, inplace=True)\n",
    "original_data.tail(10)\n",
    "\n",
    "# Fill missing values with the mode of the column\n",
    "original_data = original_data.fillna(original_data.mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                               0\n",
       "Age                                  0\n",
       "POLAR4 Quintile                      0\n",
       "POLAR3 Quintile                      0\n",
       "Adult HE 2001 Quintile               0\n",
       "Adult HE 2011 Quintile               0\n",
       "TUNDRA MSOA Quintile                 0\n",
       "TUNDRA LSOA Quintile                 0\n",
       "Gaps GCSE Quintile                   0\n",
       "Gaps GCSE Ethnicity Quintile         0\n",
       "Uni Connect target ward              0\n",
       "attending from home?                 0\n",
       "distance to university (km)          0\n",
       "Count of Module Area Logins          0\n",
       "Total Hours in Module Area           0\n",
       "% of Average Hours in Module Area    0\n",
       "# of presence                        0\n",
       "# of Absence                         0\n",
       "Percent Attended                     0\n",
       "label (fail=1, pass=0)               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check again for missing values\n",
    "original_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                                2\n",
       "Age                                  12\n",
       "POLAR4 Quintile                       5\n",
       "POLAR3 Quintile                       5\n",
       "Adult HE 2001 Quintile                5\n",
       "Adult HE 2011 Quintile                6\n",
       "TUNDRA MSOA Quintile                  6\n",
       "TUNDRA LSOA Quintile                  6\n",
       "Gaps GCSE Quintile                    6\n",
       "Gaps GCSE Ethnicity Quintile          6\n",
       "Uni Connect target ward               2\n",
       "attending from home?                  2\n",
       "distance to university (km)          46\n",
       "Count of Module Area Logins          49\n",
       "Total Hours in Module Area           78\n",
       "% of Average Hours in Module Area    78\n",
       "# of presence                        12\n",
       "# of Absence                         11\n",
       "Percent Attended                     14\n",
       "label (fail=1, pass=0)                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of unique values in each column\n",
    "original_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical columns\n",
    "categorical_cols = original_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(col, original_data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Synthetic Data Generation**\n",
    "\n",
    "Now we'll prepare for SDG and split up the original data into 30/70 test/train splits. If the splits were created earlier already, we will load the existing splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data loaded.\n"
     ]
    }
   ],
   "source": [
    "original_data_path = \"../data/original_data/3_edge_hill_university/\"\n",
    "train_file = os.path.join(original_data_path, \"train_data.csv\")\n",
    "test_file = os.path.join(original_data_path, \"test_data.csv\")\n",
    "\n",
    "if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "    train_data = pd.read_csv(train_file)\n",
    "    test_data = pd.read_csv(test_file)\n",
    "    print(\"Train and test data loaded.\")\n",
    "else:\n",
    "    # Split the data into train and test sets (70% train, 30% test) according to evaluation paper\n",
    "    train_data, test_data = train_test_split(original_data, test_size=0.3, random_state=42)\n",
    "    train_data.to_csv(train_file, index=False)\n",
    "    test_data.to_csv(test_file, index=False)\n",
    "    print(\"Train and test data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check whether the synthetic datasets were already generated. If not, use the train split to train the SDG models and sample as many entries as the train dataset contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data already exists.\n"
     ]
    }
   ],
   "source": [
    "# Set the start method of the multiprocessing module to 'fork' to avoid an error\n",
    "multiprocessing.set_start_method('fork', force=True)\n",
    "\n",
    "synth_path = \"../data/synthetic_data/3_edge_hill_university/\"\n",
    "dataset_name = \"3_edge_hill_university\"\n",
    "csv_files = [file for file in os.listdir(synth_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Number of samples to generate\n",
    "n = len(train_data)\n",
    "\n",
    "if len(csv_files) == 0:\n",
    "\n",
    "    # Use train_data.csv to fit SDG models and generate synthetic data\n",
    "    data_path = original_data_path + \"train_data.csv\"\n",
    "    arguments = [data_path, str(n), dataset_name]\n",
    "\n",
    "    print(\"Sampling synthpop...\")\n",
    "    result = subprocess.run(['Rscript', '../src/generation/synthpop.R',   *arguments], capture_output=True, text=True)\n",
    "\n",
    "    print(\"Sampling DataSynthesizer...\")\n",
    "    ds_generate_data(data_path=data_path, num_samples=n, dataset_name=dataset_name)\n",
    "\n",
    "    sdv_generate_data(data_path=data_path, num_samples=n, dataset_name=dataset_name)\n",
    "else:\n",
    "    print(\"Synthetic data already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all categorical columns of both original (train+test) data and synthetic data using label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic data as dataframe\n",
    "synthpop = pd.read_csv(synth_path + \"synthpop.csv\")\n",
    "ds = pd.read_csv(synth_path + \"ds.csv\")\n",
    "tvae = pd.read_csv(synth_path + \"tvae.csv\")\n",
    "gaussian_copula = pd.read_csv(synth_path + \"gaussian_copula.csv\")\n",
    "copula_gan = pd.read_csv(synth_path + \"copula_gan.csv\")\n",
    "ctgan = pd.read_csv(synth_path + \"ctgan.csv\")\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    test_data[col] = le.fit_transform(test_data[col])\n",
    "\n",
    "    synthpop[col] = le.fit_transform(synthpop[col])\n",
    "    ds[col] = le.fit_transform(ds[col])\n",
    "    tvae[col] = le.fit_transform(tvae[col])\n",
    "    gaussian_copula[col] = le.fit_transform(gaussian_copula[col])\n",
    "    copula_gan[col] = le.fit_transform(copula_gan[col])\n",
    "    ctgan[col] = le.fit_transform(ctgan[col])\n",
    "\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>POLAR4 Quintile</th>\n",
       "      <th>POLAR3 Quintile</th>\n",
       "      <th>Adult HE 2001 Quintile</th>\n",
       "      <th>Adult HE 2011 Quintile</th>\n",
       "      <th>TUNDRA MSOA Quintile</th>\n",
       "      <th>TUNDRA LSOA Quintile</th>\n",
       "      <th>Gaps GCSE Quintile</th>\n",
       "      <th>Gaps GCSE Ethnicity Quintile</th>\n",
       "      <th>Uni Connect target ward</th>\n",
       "      <th>attending from home?</th>\n",
       "      <th>distance to university (km)</th>\n",
       "      <th>Count of Module Area Logins</th>\n",
       "      <th>Total Hours in Module Area</th>\n",
       "      <th>% of Average Hours in Module Area</th>\n",
       "      <th># of presence</th>\n",
       "      <th># of Absence</th>\n",
       "      <th>Percent Attended</th>\n",
       "      <th>label (fail=1, pass=0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.259523</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.38</td>\n",
       "      <td>2.207852</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.327498</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.374471</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.791145</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.29</td>\n",
       "      <td>0.862037</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.488973</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.67</td>\n",
       "      <td>1.731614</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.203295</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.26</td>\n",
       "      <td>1.015081</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  POLAR4 Quintile  POLAR3 Quintile  Adult HE 2001 Quintile  \\\n",
       "0     0.0  21.0              4.0              4.0                     3.0   \n",
       "1     0.0  20.0              3.0              3.0                     2.0   \n",
       "2     0.0  20.0              1.0              1.0                     2.0   \n",
       "3     0.0  20.0              5.0              3.0                     4.0   \n",
       "4     0.0  24.0              2.0              2.0                     1.0   \n",
       "\n",
       "   Adult HE 2011 Quintile  TUNDRA MSOA Quintile  TUNDRA LSOA Quintile  \\\n",
       "0                     5.0                   3.0                   3.0   \n",
       "1                     4.0                   3.0                   3.0   \n",
       "2                     1.0                   2.0                   2.0   \n",
       "3                     4.0                   4.0                   4.0   \n",
       "4                     3.0                   1.0                   1.0   \n",
       "\n",
       "   Gaps GCSE Quintile   Gaps GCSE Ethnicity Quintile  Uni Connect target ward  \\\n",
       "0                  5.0                           5.0                      0.0   \n",
       "1                  3.0                           4.0                      0.0   \n",
       "2                  3.0                           3.0                      0.0   \n",
       "3                  5.0                           5.0                      0.0   \n",
       "4                  3.0                           4.0                      0.0   \n",
       "\n",
       "   attending from home?  distance to university (km)  \\\n",
       "0                   1.0                     3.259523   \n",
       "1                   1.0                    17.327498   \n",
       "2                   1.0                    60.791145   \n",
       "3                   1.0                    18.488973   \n",
       "4                   1.0                    14.203295   \n",
       "\n",
       "   Count of Module Area Logins  Total Hours in Module Area  \\\n",
       "0                         81.0                       70.38   \n",
       "1                         31.0                        4.47   \n",
       "2                         37.0                       10.29   \n",
       "3                         45.0                       20.67   \n",
       "4                         38.0                       13.26   \n",
       "\n",
       "   % of Average Hours in Module Area  # of presence  # of Absence  \\\n",
       "0                           2.207852            9.0           3.0   \n",
       "1                           0.374471           11.0           1.0   \n",
       "2                           0.862037           10.0           2.0   \n",
       "3                           1.731614           10.0           2.0   \n",
       "4                           1.015081            9.0           0.0   \n",
       "\n",
       "   Percent Attended  label (fail=1, pass=0)  \n",
       "0         75.000000                     0.0  \n",
       "1         91.666667                     0.0  \n",
       "2         83.333333                     0.0  \n",
       "3         83.333333                     0.0  \n",
       "4        100.000000                     0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Utility Evaluation**\n",
    "\n",
    "In order to evaluate the utility of the synthetic datasets, the following steps will executed three times, each time with a different ML model.\n",
    "\n",
    "1. Two models are trained: one using the original train data and the other one using synthetic data.\n",
    "2. The two different models will predict the target column using the test split.\n",
    "3. The difference in performance between the two models will be reported via accuracy diff, f1-score diff, and auc-roc diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for utility evalutation\n",
    "synth_datasets = [synthpop, ds, tvae, gaussian_copula, copula_gan, ctgan]\n",
    "model_names = [\"synthpop\", \"ds\", \"tvae\", \"gaussian_copula\", \"copula_gan\", \"ctgan\"]\n",
    "target_col = \"label (fail=1, pass=0)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run random forest classifier for utility evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "rf_results = {}\n",
    "rf_df = pd.read_csv(\"../data/results/tables/rf.csv\")\n",
    "rows = []\n",
    "\n",
    "if (rf_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        rf_results[model_names[i]] = run_utility_eval(train_data, test_data, synth_dataset, target_col, \"random_forest\")\n",
    "        acc_diff = rf_results[model_names[i]][\"acc_diff\"]\n",
    "        f1_diff = rf_results[model_names[i]][\"f1_diff\"]\n",
    "        roc_auc_diff = rf_results[model_names[i]][\"roc_auc_diff\"]\n",
    "        rows.append([3, model_names[i], acc_diff, f1_diff, roc_auc_diff])\n",
    "        \n",
    "    rows = pd.DataFrame(rows, columns=rf_df.columns)\n",
    "    rf_df = pd.concat([rf_df, rows], ignore_index=True)\n",
    "    rf_df.to_csv(\"../data/results/tables/rf.csv\", index=False)\n",
    "    rf_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run logistic regression for utility evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "lr_results = {}\n",
    "lr_df = pd.read_csv(\"../data/results/tables/lr.csv\")\n",
    "rows = []\n",
    "\n",
    "if (lr_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        lr_results[model_names[i]] = run_utility_eval(train_data, test_data, synth_dataset, target_col, \"logistic_regression\")\n",
    "\n",
    "        acc_diff = lr_results[model_names[i]][\"acc_diff\"]\n",
    "        f1_diff = lr_results[model_names[i]][\"f1_diff\"]\n",
    "        roc_auc_diff = lr_results[model_names[i]][\"roc_auc_diff\"]\n",
    "\n",
    "        rows.append([3, model_names[i], acc_diff, f1_diff, roc_auc_diff])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=lr_df.columns)\n",
    "    lr_df = pd.concat([lr_df, rows])\n",
    "    lr_df.to_csv(\"../data/results/tables/lr.csv\", index=False)\n",
    "    lr_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "mlp_results = {}\n",
    "mlp_df = pd.read_csv(\"../data/results/tables/mlp.csv\")\n",
    "rows = []\n",
    "\n",
    "if (mlp_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        mlp_results[model_names[i]] = run_utility_eval(train_data, test_data, synth_dataset, target_col, \"multilayer_perceptron\")\n",
    "\n",
    "        acc_diff = mlp_results[model_names[i]][\"acc_diff\"]\n",
    "        f1_diff = mlp_results[model_names[i]][\"f1_diff\"]\n",
    "        roc_auc_diff = mlp_results[model_names[i]][\"roc_auc_diff\"]\n",
    "\n",
    "        rows.append([3, model_names[i], acc_diff, f1_diff, roc_auc_diff])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=mlp_df.columns)\n",
    "    mlp_df = pd.concat([mlp_df, rows])\n",
    "    mlp_df.to_csv(\"../data/results/tables/mlp.csv\", index=False)\n",
    "    mlp_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resemblance**\n",
    "\n",
    "The resemblance dimension includes mutliple distance metrics to measure the similarity of the synthetic and real data: **Difference in pairwise correlation, Jensen-Shannon divergence, Wasserstein distance**\n",
    "\n",
    "- **Difference in pairwise correlation** is used to measure how well feature-interactions are preserved within synthetic data. First the pairwise correlation matrices for each real and synthetic data is computed. Pearson correlation coefficient is used for continuous features ( [-1,1] range) and the Theil uncer-\n",
    "tainty coefficient ([0,1] range) for categorical features\n",
    "    - lower (difference) values are better\n",
    "- **JSD** is a method for measuring similarity between two probability distributions. It is based on Kullback-Leibler divergence, but has several benefits like being symmetric and having finite values. Values are bounded between 0 and 1, where values close to 0 indicate high similarity and values close to 1 indicate almost no similarity between the distributions.\n",
    "    - lower values are better\n",
    "- **WD** is used to compare the distributions of two continuous/mixed variables, where one variable is derived from the other → how well the synthetic data emulates the distribution of the\n",
    "individual variables\n",
    "    - lower values are better\n",
    "\n",
    "\n",
    "**Difference in pairwise correlation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "corr_diff_df = pd.read_csv(\"../data/results/tables/corr_diff.csv\")\n",
    "rows = []\n",
    "\n",
    "if (corr_diff_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = pairwise_correlation_diff(train_data, synth_dataset)\n",
    "        rows.append([3,model_names[i], result])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=corr_diff_df.columns)\n",
    "    corr_diff_df = pd.concat([corr_diff_df, rows])\n",
    "    corr_diff_df.to_csv(\"../data/results/tables/corr_diff.csv\", index=False)\n",
    "    corr_diff_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jensen-Shannon Divergence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "jsd_df = pd.read_csv(\"../data/results/tables/jsd.csv\")\n",
    "rows = []\n",
    "\n",
    "if (jsd_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = jsd(train_data, synth_dataset)\n",
    "        rows.append([3,model_names[i], result])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=jsd_df.columns)\n",
    "    jsd_df = pd.concat([jsd_df, rows])\n",
    "    jsd_df.to_csv(\"../data/results/tables/jsd.csv\", index=False)\n",
    "    jsd_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wasserstein Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "wd_df = pd.read_csv(\"../data/results/tables/wd.csv\")\n",
    "rows = []\n",
    "\n",
    "if (wd_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = wd(train_data, synth_dataset)\n",
    "        rows.append([3,model_names[i], result])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=wd_df.columns)\n",
    "    wd_df = pd.concat([wd_df, rows])\n",
    "    wd_df.to_csv(\"../data/results/tables/wd.csv\", index=False)\n",
    "    wd_df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Privacy**\n",
    "\n",
    "To assess the privacy aspect of the synthetic data the metrics **Distance to closest Record (DCR)**, **Nearest Neighbour Difference Ratio (NNDR)** and **Membership Inference Attack (MIA)** will be used. \n",
    "\n",
    "- In **DCR** the euclidean distance between\n",
    "each record in original and synthetic dataset is computed. DCR is the minimum distance between a synthetic record and a original record. \n",
    "    - A value of zero indicates that the synthetic record is an identical copy of the original one -> leak of real information, higher values indicate more privacy\n",
    "\n",
    "- **NNDR** is ratio between nearest and second nearest real neighbour to any corresponding synthetic record (NNDR(s) = d1/d2) and is within [0,1]\n",
    "    - higher values indicate better privacy\n",
    "\n",
    "- **MIA** is used to assess the disclosure risk by assuming that an attacker has access to all the records of the synthetic data and to a random subset of the original data. Using a real record the attacker then tries to find the closest record in the synthetic dataset. If there is any distance below some threshold, the attacker can assume that the corresponding real record was used to generate the synthetic data.\n",
    "    - For strong privacy preservation both accuracy and precision should be below 0.5 for all thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance to closest record (DCR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "dcr_df = pd.read_csv(\"../data/results/tables/dcr.csv\")\n",
    "rows = []\n",
    "\n",
    "if (dcr_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = dcr(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, save_hist=True)\n",
    "        result_within_real = dcr(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, within=\"Original\", save_hist=True)\n",
    "        result_within_synth = dcr(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, within=\"Synthetic\", save_hist=True)\n",
    "        rows.append([3,model_names[i], result, result_within_real, result_within_synth])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=dcr_df.columns)\n",
    "    dcr_df = pd.concat([dcr_df, rows])\n",
    "    dcr_df.to_csv(\"../data/results/tables/dcr.csv\", index=False)\n",
    "    dcr_df.tail(7)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nearest Neighbor distance ratio (NNDR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry for '3_edge_hill_university' already exists\n"
     ]
    }
   ],
   "source": [
    "nndr_df = pd.read_csv(\"../data/results/tables/nndr.csv\")\n",
    "rows = []\n",
    "\n",
    "if (nndr_df[\"Dataset\"] == 3).any():\n",
    "    print(\"Entry for '3_edge_hill_university' already exists\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        result = nndr(train_data, synth_dataset)\n",
    "        result_within_real = nndr(train_data, synth_dataset, within=\"Original\")\n",
    "        result_within_synth = nndr(train_data, synth_dataset, within=\"Synthetic\")\n",
    "        rows.append([3,model_names[i], result, result_within_real, result_within_synth])\n",
    "\n",
    "    rows = pd.DataFrame(rows, columns=nndr_df.columns)\n",
    "    nndr_df = pd.concat([nndr_df, rows])\n",
    "    nndr_df.to_csv(\"../data/results/tables/nndr.csv\", index=False)\n",
    "    nndr_df.tail(7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Membership Inference Attack (MIA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIA results already exist.\n"
     ]
    }
   ],
   "source": [
    "mia_results = {}\n",
    "if (os.path.isfile(\"../data/results/plots/mia/3_edge_hill_university/ds_mia_accuracy.png\")):\n",
    "    print(\"MIA results already exist.\")\n",
    "else:\n",
    "    for i, synth_dataset in enumerate(synth_datasets):\n",
    "        mia_results[model_names[i]] = mia(train_data, synth_dataset, model_names[i], dataset_name=dataset_name, save_plts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt-sdg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
